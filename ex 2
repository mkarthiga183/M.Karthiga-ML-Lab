import math
from collections import Counter

# Dataset
data = [
    {'Fever': 'Yes', 'Cough': 'Yes', 'Fatigue': 'Yes', 'Disease': 'Yes'},
    {'Fever': 'Yes', 'Cough': 'Yes', 'Fatigue': 'No', 'Disease': 'Yes'},
    {'Fever': 'Yes', 'Cough': 'No', 'Fatigue': 'Yes', 'Disease': 'Yes'},
    {'Fever': 'No', 'Cough': 'Yes', 'Fatigue': 'Yes', 'Disease': 'No'},
    {'Fever': 'No', 'Cough': 'Yes', 'Fatigue': 'No', 'Disease': 'No'},
    {'Fever': 'No', 'Cough': 'No', 'Fatigue': 'Yes', 'Disease': 'No'},
    {'Fever': 'Yes', 'Cough': 'No', 'Fatigue': 'No', 'Disease': 'Yes'},
    {'Fever': 'No', 'Cough': 'No', 'Fatigue': 'No', 'Disease': 'No'}
]

# Function to calculate entropy
def entropy(dataset):
    total = len(dataset)
    label_count = Counter([row['Disease'] for row in dataset])
    ent = 0
    for count in label_count.values():
        prob = count / total
        ent -= prob * math.log2(prob)
    return ent

# Function to calculate information gain
def info_gain(dataset, attribute):
    total_entropy = entropy(dataset)
    total = len(dataset)
   
    values = set(row[attribute] for row in dataset)
    weighted_entropy = 0
   
    for value in values:
        subset = [row for row in dataset if row[attribute] == value]
        weighted_entropy += (len(subset) / total) * entropy(subset)
   
    return total_entropy - weighted_entropy

# ID3 Algorithm
def id3(dataset, attributes):
    labels = [row['Disease'] for row in dataset]
   
    # If all labels same → return label
    if labels.count(labels[0]) == len(labels):
        return labels[0]
   
    # If no attributes left → return majority
    if not attributes:
        return Counter(labels).most_common(1)[0][0]
   
    # Select best attribute
    gains = {attr: info_gain(dataset, attr) for attr in attributes}
    best_attr = max(gains, key=gains.get)
   
    tree = {best_attr: {}}
    values = set(row[best_attr] for row in dataset)
   
    for value in values:
        subset = [row for row in dataset if row[best_attr] == value]
        if not subset:
            tree[best_attr][value] = Counter(labels).most_common(1)[0][0]
        else:
            remaining_attrs = [attr for attr in attributes if attr != best_attr]
            tree[best_attr][value] = id3(subset, remaining_attrs)
   
    return tree

# Build decision tree
attributes = ['Fever', 'Cough', 'Fatigue']
decision_tree = id3(data, attributes)

print("Decision Tree:")
print(decision_tree)                   

OUTPUT:

Decision Tree:
{'Fever': {'Yes': 'Yes', 'No': 'No'}}
